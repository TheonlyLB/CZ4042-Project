{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61884c60-07d6-41da-9e9e-7e53b49b9252",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.9.10-py3-none-any.whl.metadata (59 kB)\n",
      "     ---------------------------------------- 0.0/59.8 kB ? eta -:--:--\n",
      "     ------------- ------------------------ 20.5/59.8 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 59.8/59.8 kB 787.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.7 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from timm) (2.1.0+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from timm) (0.16.0)\n",
      "Collecting pyyaml (from timm)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub (from timm)\n",
      "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.4.0-cp311-none-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from torch>=1.7->timm) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from torch>=1.7->timm) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from torch>=1.7->timm) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from torch>=1.7->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from torch>=1.7->timm) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from huggingface-hub->timm) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub->timm)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from huggingface-hub->timm) (23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from torchvision->timm) (1.26.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from torchvision->timm) (10.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from requests->huggingface-hub->timm) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jayyx\\documents\\github\\cz4042-project\\.venv\\lib\\site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
      "Downloading timm-0.9.10-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.2 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.7/2.2 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/302.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 302.0/302.0 kB 9.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 144.7/144.7 kB 8.4 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.0-cp311-none-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 277.4/277.4 kB 8.3 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, pyyaml, huggingface-hub, timm\n",
      "Successfully installed huggingface-hub-0.18.0 pyyaml-6.0.1 safetensors-0.4.0 timm-0.9.10 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403e248b-e7c7-4dae-ad06-7161fb402dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayyx\\Documents\\GitHub\\CZ4042-Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "import torchvision.transforms as tfms\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f1e1c-c534-40fc-8057-01bd8b0da238",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156e08dd-21f0-442b-9845-c994c1230b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"datasets\"\n",
    "# Run below cell if dataset not downloaded yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c5680e-baa3-466a-99ce-1ac79e75e8a5",
   "metadata": {},
   "source": [
    "### Run below cell if dataset not downloaded yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bffbe2-1bf9-4553-90dd-2b65715067a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root = \"datasets\"\n",
    "\n",
    "# base_url = \"https://graal.ift.ulaval.ca/public/celeba/\"\n",
    "\n",
    "# file_list = [\n",
    "#     \"img_align_celeba.zip\",\n",
    "#     \"list_attr_celeba.txt\",\n",
    "#     \"identity_CelebA.txt\",\n",
    "#     \"list_bbox_celeba.txt\",\n",
    "#     \"list_landmarks_align_celeba.txt\",\n",
    "#     \"list_eval_partition.txt\",\n",
    "# ]\n",
    "\n",
    "# # Path to folder with the dataset\n",
    "# dataset_folder = f\"{data_root}/celeba\"\n",
    "# os.makedirs(dataset_folder, exist_ok=True)\n",
    "\n",
    "# for file in file_list:\n",
    "#     url = f\"{base_url}/{file}\"\n",
    "#     if not os.path.exists(f\"{dataset_folder}/{file}\"):\n",
    "#         wget.download(url, f\"{dataset_folder}/{file}\")\n",
    "\n",
    "# with zipfile.ZipFile(f\"{dataset_folder}/img_align_celeba.zip\", \"r\") as ziphandler:\n",
    "#     ziphandler.extractall(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a98df4a-62fb-46c5-85f6-ff1b13c350e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_size = 224\n",
    "w, h = 218, 178  # the width and the hight of original images before resizing\n",
    "gender_index = 20  # in the CelebA dataset gender information is the 21th item in the attributes vector.\n",
    "imagenet_mean = [0.485, 0.456, 0.406]  # mean of the ImageNet dataset for normalizing\n",
    "imagenet_std = [0.229, 0.224, 0.225]  # std of the ImageNet dataset for normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c9d092-a2a3-43e5-9763-7896107d70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tfms.Compose(\n",
    "    [\n",
    "        tfms.Resize((image_size, image_size)),\n",
    "        tfms.ToTensor(),\n",
    "        tfms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]\n",
    ")\n",
    "train_dataset = datasets.CelebA(data_root, split=\"train\", target_type=[\"attr\"], transform=transforms)\n",
    "valid_dataset = datasets.CelebA(data_root, split=\"valid\", target_type=[\"attr\"], transform=transforms)\n",
    "test_dataset = datasets.CelebA(data_root, split=\"test\", target_type=[\"attr\"], transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb65d58f-160d-4fe2-9c28-57d89cf46edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only taking part of the dataset to train\n",
    "train_num = 5000\n",
    "train_ratio = 0.7\n",
    "\n",
    "train_subset = Subset(train_dataset, np.arange(1, int(train_num*train_ratio)))\n",
    "valid_subset = Subset(valid_dataset, np.arange(1, int(train_num*(1-train_ratio))))\n",
    "test_subset = Subset(test_dataset, np.arange(1, 1000))\n",
    "train_dataloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_subset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586dae17-aef2-4a16-888f-deb0caea2fb4",
   "metadata": {},
   "source": [
    "# Custom Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac2d7cda-f3a2-439e-8466-d6cccebeeca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationRegressionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationRegressionLoss, self).__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()  # size_average=False\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss_cls = self.ce_loss(y_pred, y_true[:, gender_index])  # Cross Entropy Error (for classification)\n",
    "        return loss_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca5f21-30b4-4d3b-a520-9b24dbbcd47f",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebe78bc-06cf-4722-ad4b-fded0ad8760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The running processor is... cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The running processor is...\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c7fedc0-3125-4126-9b7d-1cf489d401fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = ClassificationRegressionLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9bf7e8f-d19a-4341-8911-cc083b629594",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['inception_resnet_v2','inception_v4']\n",
    "# learning_rate_list = [0.01,0.005,0.001]\n",
    "learning_rate_list = [0.01]\n",
    "# optimizer_list = ['SGD','RMSprop', 'Adam'] # 'SGD'\n",
    "optimizer_list = ['SGD']\n",
    "# momentum_list = [0.0, 0.2, 0.4]\n",
    "momentum_list = [0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "648dcbf8-9e2e-4354-8336-83464aef96a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jayyx\\Documents\\GitHub\\CZ4042-Project\\inception_model_testing.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jayyx/Documents/GitHub/CZ4042-Project/inception_model_testing.ipynb#X21sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39m# Calculate the number of correct predictions\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jayyx/Documents/GitHub/CZ4042-Project/inception_model_testing.ipynb#X21sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     corrects \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(preds \u001b[39m==\u001b[39m binary_labels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jayyx/Documents/GitHub/CZ4042-Project/inception_model_testing.ipynb#X21sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jayyx/Documents/GitHub/CZ4042-Project/inception_model_testing.ipynb#X21sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jayyx/Documents/GitHub/CZ4042-Project/inception_model_testing.ipynb#X21sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m cur_epoch_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for model in model_list:\n",
    "    # Initialize the Inception model\n",
    "    model_name = model\n",
    "    model = timm.create_model(model, pretrained=True, num_classes=2)\n",
    "    model.to(device)\n",
    "    \n",
    "    for optimizer_name in optimizer_list:\n",
    "        for learning_rate in learning_rate_list:\n",
    "          for momentum in momentum_list:\n",
    "        \n",
    "            if optimizer_name == 'SGD':\n",
    "              optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "            elif optimizer_name == 'RMSprop':\n",
    "              optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "            elif optimizer_name == 'Adam':\n",
    "              optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "            log_filename = f'saves/{model_name}_{optimizer_name}_{momentum}_{learning_rate}.tsv'\n",
    "            \n",
    "            with open(log_filename, 'w', newline='') as log_file:\n",
    "                log_writer = csv.writer(log_file, delimiter='\\t')\n",
    "            \n",
    "                # Write the header row to the log file\n",
    "                log_writer.writerow(['epoch', 'time', 'lr', 'loss', 'val_loss'])\n",
    "            \n",
    "                for epoch in range(num_epochs):\n",
    "                    print(f'Starting epoch {epoch}')\n",
    "                    epoch_start_time = time.time()\n",
    "                    for phase in ['train', 'val']:\n",
    "                        start_time = time.time()\n",
    "                        if phase == 'train':\n",
    "                            model.train()\n",
    "                            dataloader = train_dataloader\n",
    "                        else:\n",
    "                            model.eval()\n",
    "                            dataloader = valid_dataloader\n",
    "                \n",
    "                        running_loss = 0.0\n",
    "                        corrects = 0\n",
    "                \n",
    "                        for inputs, labels in dataloader:\n",
    "                            inputs = inputs.to(device)\n",
    "                            labels = labels.to(device)\n",
    "                \n",
    "                            optimizer.zero_grad()\n",
    "                \n",
    "                            with torch.set_grad_enabled(phase == 'train'):\n",
    "                                outputs = model(inputs)\n",
    "                                loss = criterion(outputs, labels)\n",
    "                \n",
    "                                if phase == 'train':\n",
    "                                    loss.backward()\n",
    "                                    optimizer.step()\n",
    "                \n",
    "                            # Calculate the number of correct predictions for binary classification\n",
    "                            _, preds = torch.max(outputs, 1)\n",
    "                            \n",
    "                            # Assuming labels.data is a 2D tensor of shape [batch_size, num_classes], you need to extract the binary class labels\n",
    "                            # If labels.data contains multiple columns, you can get the binary class labels from one of the columns\n",
    "                            binary_labels = labels.data[:, gender_index].to(device)\n",
    "                        \n",
    "                            # Calculate the number of correct predictions\n",
    "                            corrects += torch.sum(preds == binary_labels)\n",
    "                        \n",
    "                            running_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                        end_time = time.time()\n",
    "                        cur_epoch_time = end_time - start_time\n",
    "            \n",
    "                        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "                        \n",
    "                        if phase == 'train':\n",
    "                            train_loss = epoch_loss\n",
    "                        else:\n",
    "                            val_loss = epoch_loss\n",
    "                            \n",
    "                        epoch_acc = corrects.double() / len(dataloader.dataset)\n",
    "                        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                        print(f'Time taken for {epoch} {phase} epoch: {cur_epoch_time:.2f} seconds')\n",
    "                    \n",
    "                    full_epoch_time = time.time() - epoch_start_time\n",
    "                    # Record the learning rate\n",
    "                    current_lr = optimizer.param_groups[0]['lr']\n",
    "                    log_writer.writerow([epoch + 1, full_epoch_time, current_lr, train_loss, val_loss])  # You need to compute validation loss\n",
    "\n",
    "                # Save the trained model\n",
    "                # torch.save(model.state_dict(), 'inceptionv4_celeba.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
